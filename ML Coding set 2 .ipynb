{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Identify Customers with High Purchase Frequency\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Customer_ID': [101, 102, 103, 101, 104, 102, 101, 105, 102, 103],\n",
    "        'Purchase_Amount': [200, 150, 180, 220, 300, 200, 100, 400, 250, 300]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Task:\n",
    "Group customers by Customer_ID and count the number of purchases per customer.\n",
    "\n",
    "Identify the top 3 customers with the highest number of purchases.\n",
    "\n",
    "Expected Output:\n",
    "    Customer Purchase Frequency:\n",
    "   Customer_ID  Purchase_Count\n",
    "0         101               3\n",
    "1         102               3\n",
    "2         103               2\n",
    "3         104               1\n",
    "4         105               1\n",
    "\n",
    "Top 3 Frequent Customers:\n",
    "   Customer_ID  Purchase_Count\n",
    "0         101               3\n",
    "1         102               3\n",
    "2         103               2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f38763c5-7a12-41db-a485-93f0b8861586",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 9) (4246706428.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[69], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    top_students = df.sort_values(by=Purchase_Score',ascending= False).head(3)\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Customer_ID': [101, 102, 103, 101, 104, 102, 101, 105, 102, 103],\n",
    "        'Purchase_Amount': [200, 150, 180, 220, 300, 200, 100, 400, 250, 300]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "Purchase_Score = df.groupby('Customer_ID')['Purchase_Amount'].count()\n",
    "print(\"Customer Purchase Frequency:\",Purchase_Score)\n",
    "top_students = df.sort_values(by=Purchase_Amount',ascending= False).head(3)\n",
    "print(\"Top 3 Frequent Customers:\",top_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Find Students with the Highest Average Exam Scores\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Student_ID': [201, 202, 203, 201, 204, 202, 201, 205, 202, 203],\n",
    "        'Exam_Score': [85, 90, 78, 88, 92, 87, 80, 95, 89, 84]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "Task:\n",
    "Calculate the average exam score per student.\n",
    "\n",
    "Display the top 3 students with the highest average scores.\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "Average Exam Scores per Student:\n",
    "   Student_ID  Avg_Score\n",
    "0        201   84.33\n",
    "1        202   88.67\n",
    "2        203   81.00\n",
    "3        204   92.00\n",
    "4        205   95.00\n",
    "\n",
    "Top 3 Students:\n",
    "   Student_ID  Avg_Score\n",
    "0        205   95.00\n",
    "1        204   92.00\n",
    "2        202   88.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcbc72fc-a680-41b7-bd9c-505e00de4eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Exam Scores per Student:\n",
      "Student_ID\n",
      "201    84.333333\n",
      "202    88.666667\n",
      "203    81.000000\n",
      "204    92.000000\n",
      "205    95.000000\n",
      "Name: Exam_Score, dtype: float64\n",
      "Top 3 Students:    Student_ID  Exam_Score\n",
      "7         205          95\n",
      "4         204          92\n",
      "1         202          90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Student_ID': [201, 202, 203, 201, 204, 202, 201, 205, 202, 203],\n",
    "        'Exam_Score': [85, 90, 78, 88, 92, 87, 80, 95, 89, 84]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "average_Score = df.groupby('Student_ID')['Exam_Score'].mean()\n",
    "print(\"Average Exam Scores per Student:\")\n",
    "print(average_Score)\n",
    "top_students = df.nlargest(3,'Exam_Score')\n",
    "print(\"Top 3 Students:\",top_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Predict House Prices Using Linear Regression\n",
    "Dataset:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Size_sqft': [1500, 1800, 2400, 3000, 3500, 4000],\n",
    "        'Price': [300000, 350000, 450000, 550000, 650000, 700000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "Task:\n",
    "Train a Linear Regression model to predict house prices based on Size_sqft.\n",
    "\n",
    "Predict the price of a house of size 2800 sqft.\n",
    "\n",
    "Expected Output:\n",
    "Predicted Price for 2800 sqft: $516491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ca9d31-ed1f-422c-8dc2-77fbc5f6c5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Size_sqft   Price\n",
      "0       1500  300000\n",
      "1       1800  350000\n",
      "2       2400  450000\n",
      "3       3000  550000\n",
      "4       3500  650000\n",
      "5       4000  700000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m     13\u001b[0m regressor \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 14\u001b[0m regressor\u001b[38;5;241m.\u001b[39mfit(X,Y)\n\u001b[0;32m     15\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39mregressor\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:609\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    605\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    607\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 609\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    610\u001b[0m     X,\n\u001b[0;32m    611\u001b[0m     y,\n\u001b[0;32m    612\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m    613\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    614\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    615\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    616\u001b[0m )\n\u001b[0;32m    618\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Size_sqft': [1500, 1800, 2400, 3000, 3500, 4000],\n",
    "        'Price': [300000, 350000, 450000, 550000, 650000, 700000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df) \n",
    "X = df[ 'Size_sqft']\n",
    "Y = df['Price']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,Y_train,X_test,Y_test = train_test_split(X,Y,test_size=0.33,random_state =0)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X,Y)\n",
    "Y_pred =regressor.predict(X)\n",
    "from sklearn.metrics import r2_score\n",
    "r_score = r2_score(Y_test,Y_pred)\n",
    "r_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Identify the Most Commonly Purchased Products\n",
    "dataset:\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Product_ID': ['P101', 'P102', 'P103', 'P101', 'P104', 'P102', 'P101', 'P105', 'P102', 'P103'],\n",
    "        'Purchase_Count': [5, 3, 4, 2, 1, 6, 7, 3, 2, 5]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "Task:\n",
    "Group products by Product_ID and sum their Purchase_Count.\n",
    "\n",
    "Identify the top 3 most purchased products.\n",
    "\n",
    "Expected Output:\n",
    "\n",
    "Product Purchase Counts:\n",
    "   Product_ID  Total_Purchases\n",
    "0       P101               14\n",
    "1       P102               11\n",
    "2       P103                9\n",
    "3       P104                1\n",
    "4       P105                3\n",
    "\n",
    "Top 3 Purchased Products:\n",
    "   Product_ID  Total_Purchases\n",
    "0       P101               14\n",
    "1       P102               11\n",
    "2       P103                9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66d373fe-a8f3-41f5-a1f6-db748a3e27dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Purchase Counts: Product_ID\n",
      "P101    14\n",
      "P102    11\n",
      "P103     9\n",
      "P104     1\n",
      "P105     3\n",
      "Name: Purchase_Count, dtype: int64\n",
      "Top 3 Purchased Products:   Product_ID  Purchase_Count\n",
      "6       P101               7\n",
      "5       P102               6\n",
      "0       P101               5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Product_ID': ['P101', 'P102', 'P103', 'P101', 'P104', 'P102', 'P101', 'P105', 'P102', 'P103'],\n",
    "        'Purchase_Count': [5, 3, 4, 2, 1, 6, 7, 3, 2, 5]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "product = df.groupby('Product_ID')['Purchase_Count'].sum()\n",
    "print(\"Product Purchase Counts:\" ,product)\n",
    "top_products = df.nlargest(3,['Purchase_Count'])\n",
    "print(\"Top 3 Purchased Products:\",top_products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d4ea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Cluster Customers Based on Their Purchase Amounts\n",
    "Dataset:\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Customer_ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'Total_Spend': [500, 1500, 2000, 2500, 3000, 3500, 4000, 1000, 1200, 2700]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "Task:\n",
    "Apply K-Means Clustering to segment customers into 3 clusters.\n",
    "\n",
    "Print the cluster labels for each customer.\n",
    "\n",
    "Expected Output:\n",
    "Customer Clusters:\n",
    "   Customer_ID  Total_Spend  Cluster_Label\n",
    "0            1          500              1\n",
    "1            2         1500              1\n",
    "2            3         2000              2\n",
    "3            4         2500              2\n",
    "4            5         3000              2\n",
    "5            6         3500              0\n",
    "6            7         4000              0\n",
    "7            8         1000              1\n",
    "8            9         1200              1\n",
    "9           10         2700              2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3b00eee2-b1d7-4e43-a214-8be5fa912855",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer_ID\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Spend\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m1500\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m2500\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m3500\u001b[39m, \u001b[38;5;241m4000\u001b[39m, \u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1200\u001b[39m, \u001b[38;5;241m2700\u001b[39m]}\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m----> 6\u001b[0m x \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      8\u001b[0m kmeans \u001b[38;5;241m=\u001b[39mKMeans(n_clusters \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m'\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Customer_ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'Total_Spend': [500, 1500, 2000, 2500, 3000, 3500, 4000, 1000, 1200, 2700]}\n",
    "df = pd.DataFrame(data)\n",
    "x = df.iloc[:,[1,2].values]\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans =KMeans(n_clusters =3,init='k-means++',random_state=42)\n",
    "y_kmeans = kmeans.predict(x)\n",
    "y_kmeans\n",
    "supervised = df\n",
    "supervised['Cluster_Label'] = y_kmeans\n",
    "supervised\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69f7a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSY MOBILES\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\SSY MOBILES\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Clusters:\n",
      "   Customer_ID  Total_Spend  Cluster_Label\n",
      "0            1          500              0\n",
      "1            2         1500              0\n",
      "2            3         2000              2\n",
      "3            4         2500              2\n",
      "4            5         3000              2\n",
      "5            6         3500              1\n",
      "6            7         4000              1\n",
      "7            8         1000              0\n",
      "8            9         1200              0\n",
      "9           10         2700              2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SSY MOBILES\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#5.sln:\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Creating the DataFrame\n",
    "data = {'Customer_ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'Total_Spend': [500, 1500, 2000, 2500, 3000, 3500, 4000, 1000, 1200, 2700]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying K-Means Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "df['Cluster_Label'] = kmeans.fit_predict(df[['Total_Spend']])\n",
    "\n",
    "print(\"Customer Clusters:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f73179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf02fcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
